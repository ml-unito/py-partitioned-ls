<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1"/>
    <meta name="generator" content="pdoc 0.9.1"/>
    <title> API documentation</title>
    <meta name="description" content="Partitioned Least Square"/>
    <link rel="preload stylesheet" as="style"
          href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
          integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
    <link rel="preload stylesheet" as="style"
          href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
          integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
    <link rel="stylesheet preload" as="style"
          href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
    <style>
        :root {
            --highlight-color: #fe9
        }

        .flex {
            display: flex !important
        }

        body {
            line-height: 1.5em
        }

        #content {
            padding: 20px
        }

        #sidebar {
            padding: 30px;
            overflow: hidden
        }

        #sidebar > *:last-child {
            margin-bottom: 2cm
        }

        .http-server-breadcrumbs {
            font-size: 130%;
            margin: 0 0 15px 0
        }

        #footer {
            font-size: .75em;
            padding: 5px 30px;
            border-top: 1px solid #ddd;
            text-align: right
        }

        #footer p {
            margin: 0 0 0 1em;
            display: inline-block
        }

        #footer p:last-child {
            margin-right: 30px
        }

        h1, h2, h3, h4, h5 {
            font-weight: 300
        }

        h1 {
            font-size: 2.5em;
            line-height: 1.1em
        }

        h2 {
            font-size: 1.75em;
            margin: 1em 0 .50em 0
        }

        h3 {
            font-size: 1.4em;
            margin: 25px 0 10px 0
        }

        h4 {
            margin: 0;
            font-size: 105%
        }

        h1:target, h2:target, h3:target, h4:target, h5:target, h6:target {
            background: var(--highlight-color);
            padding: .2em 0
        }

        a {
            color: #058;
            text-decoration: none;
            transition: color .3s ease-in-out
        }

        a:hover {
            color: #e82
        }

        .title code {
            font-weight: bold
        }

        h2[id^="header-"] {
            margin-top: 2em
        }

        .ident {
            color: #900
        }

        pre code {
            background: #f8f8f8;
            font-size: .8em;
            line-height: 1.4em
        }

        code {
            background: #f2f2f1;
            padding: 1px 4px;
            overflow-wrap: break-word
        }

        h1 code {
            background: transparent
        }

        pre {
            background: #f8f8f8;
            border: 0;
            border-top: 1px solid #ccc;
            border-bottom: 1px solid #ccc;
            margin: 1em 0;
            padding: 1ex
        }

        #http-server-module-list {
            display: flex;
            flex-flow: column
        }

        #http-server-module-list div {
            display: flex
        }

        #http-server-module-list dt {
            min-width: 10%
        }

        #http-server-module-list p {
            margin-top: 0
        }

        .toc ul, #index {
            list-style-type: none;
            margin: 0;
            padding: 0
        }

        #index code {
            background: transparent
        }

        #index h3 {
            border-bottom: 1px solid #ddd
        }

        #index ul {
            padding: 0
        }

        #index h4 {
            margin-top: .6em;
            font-weight: bold
        }

        @media (min-width: 200ex) {
            #index .two-column {
                column-count: 2
            }
        }

        @media (min-width: 300ex) {
            #index .two-column {
                column-count: 3
            }
        }

        dl {
            margin-bottom: 2em
        }

        dl dl:last-child {
            margin-bottom: 4em
        }

        dd {
            margin: 0 0 1em 3em
        }

        #header-classes + dl > dd {
            margin-bottom: 3em
        }

        dd dd {
            margin-left: 2em
        }

        dd p {
            margin: 10px 0
        }

        .name {
            background: #eee;
            font-weight: bold;
            font-size: .85em;
            padding: 5px 10px;
            display: inline-block;
            min-width: 40%
        }

        .name:hover {
            background: #e0e0e0
        }

        dt:target .name {
            background: var(--highlight-color)
        }

        .name > span:first-child {
            white-space: nowrap
        }

        .name.class > span:nth-child(2) {
            margin-left: .4em
        }

        .inherited {
            color: #999;
            border-left: 5px solid #eee;
            padding-left: 1em
        }

        .inheritance em {
            font-style: normal;
            font-weight: bold
        }

        .desc h2 {
            font-weight: 400;
            font-size: 1.25em
        }

        .desc h3 {
            font-size: 1em
        }

        .desc dt code {
            background: inherit
        }

        .source summary, .git-link-div {
            color: #666;
            text-align: right;
            font-weight: 400;
            font-size: .8em;
            text-transform: uppercase
        }

        .source summary > * {
            white-space: nowrap;
            cursor: pointer
        }

        .git-link {
            color: inherit;
            margin-left: 1em
        }

        .source pre {
            max-height: 500px;
            overflow: auto;
            margin: 0
        }

        .source pre code {
            font-size: 12px;
            overflow: visible
        }

        .hlist {
            list-style: none
        }

        .hlist li {
            display: inline
        }

        .hlist li:after {
            content: ',\2002'
        }

        .hlist li:last-child:after {
            content: none
        }

        .hlist .hlist {
            display: inline;
            padding-left: 1em
        }

        img {
            max-width: 100%
        }

        td {
            padding: 0 .5em
        }

        .admonition {
            padding: .1em .5em;
            margin-bottom: 1em
        }

        .admonition-title {
            font-weight: bold
        }

        .admonition.note, .admonition.info, .admonition.important {
            background: #aef
        }

        .admonition.todo, .admonition.versionadded, .admonition.tip, .admonition.hint {
            background: #dfd
        }

        .admonition.warning, .admonition.versionchanged, .admonition.deprecated {
            background: #fd4
        }

        .admonition.error, .admonition.danger, .admonition.caution {
            background: lightpink
        }
    </style>
    <style media="screen and (min-width: 700px)">
        @media screen and (min-width: 700px) {
            #sidebar {
                width: 30%;
                height: 100vh;
                overflow: auto;
                position: sticky;
                top: 0
            }

            #content {
                width: 70%;
                max-width: 100ch;
                padding: 3em 4em;
                border-left: 1px solid #ddd
            }

            pre code {
                font-size: 1em
            }

            .item .name {
                font-size: 1em
            }

            main {
                display: flex;
                flex-direction: row-reverse;
                justify-content: flex-end
            }

            .toc ul ul, #index ul {
                padding-left: 1.5em
            }

            .toc > ul > li {
                margin-top: .5em
            }
        }
    </style>
    <style
            media="print">@media print {
        #sidebar h1 {
            page-break-before: always
        }

        .source {
            display: none
        }
    }

    @media print {
        * {
            background: transparent !important;
            color: #000 !important;
            box-shadow: none !important;
            text-shadow: none !important
        }

        a[href]:after {
            content: " (" attr(href) ")";
            font-size: 90%
        }

        a[href][title]:after {
            content: none
        }

        abbr[title]:after {
            content: " (" attr(title) ")"
        }

        .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
            content: ""
        }

        pre, blockquote {
            border: 1px solid #999;
            page-break-inside: avoid
        }

        thead {
            display: table-header-group
        }

        tr, img {
            page-break-inside: avoid
        }

        img {
            max-width: 100% !important
        }

        @page {
            margin: 0.5cm
        }

        p, h2, h3 {
            orphans: 3;
            widows: 3
        }

        h1, h2, h3, h4, h5, h6 {
            page-break-after: avoid
        }
    }
    </style>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"
            integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
    <script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
    <article id="base">
        <header>
            <h1 class="title">Module <code>_base</code></h1>
        </header>
        <section id="section-intro">
            <p>Partitioned Least Square class</p>
            <p>Developer:
                Omar Billotti</p>
            <p>Description:
                Partitioned Least Square class</p>
            <details class="source">
                <summary>
                    <span>Expand source code</span>
                </summary>
                <pre><code class="python">#!/usr/bin/env python
&#34;&#34;&#34;
Partitioned Least Square class

Developer:
Omar Billotti

Description:
Partitioned Least Square class
&#34;&#34;&#34;
from numpy import shape, zeros, hstack, ones, vstack, sum as sum_elements, array, inf, where
from numpy.random import rand
from numpy.linalg import lstsq
from scipy.optimize import nnls
from scipy.linalg import norm

from partitioned_ls._utils import vec1, indextobeta, checkalpha, bmatrix


class PartitionedLs(object):
    &#34;&#34;&#34;
    Partitioned Least Square class
    &#34;&#34;&#34;

    def __init__(self, algorithm=&#34;alt&#34;):
        &#34;&#34;&#34;
            Constructor of Partioned Least Square Class

            Parameters
            ----------
            algorithm : string
                        String used to set some algorithm to choose to create
                        the model. possible values alt and opt


            Returns
            -------
            None.
        &#34;&#34;&#34;
        self.model = None
        self.algorithm = algorithm

    def fit(self, x, y, p):
        &#34;&#34;&#34;
            Fits a PartialLS Regression model to the given data

            Parameters
            ----------
            x : Matrix
                describing the examples
            y : Array
                vector with the output values for each example
            p : Matrix
                specifying how to partition the M attributes into K subsets.
                P{m,k} should be 1 if attribute number m belongs to partition k

            Returns
            -------
            None.
        &#34;&#34;&#34;
        if self.algorithm == &#34;opt&#34;:
            self.__fit_opt_nnls(x, y, p)
        elif self.algorithm == &#34;alt&#34;:
            self.__fit_alt_nnls(x, y, p)
        else:
            self.__fit_alt_nnls(x, y, p)

    def __fit_opt_nnls(self, x,
                       y, p):
        &#34;&#34;&#34;
            Fits a PartialLS OPT Regression model to the given data

            Parameters
            ----------
            x : Matrix
                describing the examples
            y : Array
                vector with the output values for each example
            p : Matrix
                specifying how to partition the M attributes into K subsets.
                P{m,k} should be 1 if attribute number m belongs to partition k

            Returns
            -------
            None.
        &#34;&#34;&#34;
        xo = hstack((x, ones((shape(x)[0], 1))))
        po = vstack(
            (hstack((p, zeros((shape(p)[0], 1)))), vec1(shape(p)[1] + 1)))

        k = shape(po)[1]

        b_start, results = (-1, [])

        for i in range(b_start + 1, 2 ** k):
            beta = array(indextobeta(i, k))
            xb = bmatrix(xo, po, beta)
            alpha = nnls(xb, y)[0]
            optval = norm(xo.dot(po * alpha.reshape(-1, 1)).dot(beta) - y)

            result = (optval, alpha[:-1], beta[:-1], alpha[-1] * beta[-1], p)
            results.append(result)

        optvals = [r[0] for r in results]
        optindex = optvals.index(min(optvals))

        (opt, a, b, t, p) = results[optindex]

        A = sum_elements(p * a.reshape(-1, 1), 0)
        b = b * A

        # substituting all 0.0 with 1.0
        for z in where(A == 0.0):
            A[z] = 1.0

        a = sum_elements((p * a.reshape(-1, 1)) / A, 1)

        self.model = (opt, a, b, t, p)

    def __fit_alt_nnls(self, x,
                       y, p,
                       n=20):
        &#34;&#34;&#34;
            Fits a PartialLS Alt Regression model to the given data

            Parameters
            ----------
            x : Matrix N * M
                matrix describing the examples
            y : vector
                vector with the output values for each example
            p : Matrix M * K
                specifying how to partition the M attributes into K subsets.
                P{m,k} should be 1 if attribute number m belongs to partition k
            n : int
                number of alternating loops to be performed, defaults to 20.

            Returns
            -------
            None.
        &#34;&#34;&#34;

        # Rewriting the problem in homogenous coordinates
        xo = hstack((x, ones((shape(x)[0], 1))))
        po = vstack((hstack((p, zeros((shape(p)[0], 1)))),
                     vec1(shape(p)[1] + 1)))

        m, k = shape(po)

        alpha = rand(m)
        beta = (rand(k) - 0.5) * 10
        t = rand()

        initvals = (0, alpha, beta, t, inf)

        i_start, alpha, beta, t, optval = initvals

        for i in range(i_start + 1, n):
            # nnls problem with fixed beta variables
            po_beta = sum_elements(po * beta, 1)
            xo_beta = xo * po_beta
            alpha = nnls(xo_beta, y)[0]
            alpha = checkalpha(alpha, po)

            sum_alpha = sum_elements(po * alpha.reshape(-1, 1), 0)
            po_alpha = sum_elements(po * sum_alpha, 1)
            alpha = alpha / po_alpha
            beta = beta * sum_alpha

            # ls problem with fixed alpha variables
            xo_alpha = xo.dot(po * alpha.reshape(-1, 1))
            beta = lstsq(xo_alpha, y, rcond=None)[0]
            optval = norm(xo.dot(po * alpha.reshape(-1, 1)).dot(beta) - y, 2)

        self.model = (optval, alpha[:-1], beta[:-1], alpha[-1] * beta[-1], p)

    def predict(self, x):
        &#34;&#34;&#34;
            Description
            Predicts points using the formula: f(X) = X * (P .* a) * b + t.

            Parameters
            ----------
            x : Matrix N * M
                    matrix describing the examples

            Returns
            -------
            out : Array
             contains the predictions of the given model on examples in X
        &#34;&#34;&#34;
        (_, alpha, beta, t, p) = self.model
        return array(x).dot(p * alpha.reshape(-1, 1)).dot(beta) + t</code></pre>
            </details>
        </section>
        <section>
            <h2 class="section-title" id="header-classes">Classes</h2>
            <dl>
                <dt id="_base.PartitionedLs"><code class="flex name class">
                    <span>class <span class="ident">PartitionedLs</span></span>
                    <span>(</span><span>algorithm='alt')</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Partitioned Least Square class</p>
                        <p>Constructor of Partioned Least Square Class</p>
                        <h2 id="parameters">Parameters</h2>
                        <dl>
                            <dt><strong><code>algorithm</code></strong> :&ensp;<code>string</code></dt>
                            <dd>String used to set some algorithm to choose to create
                                the model. possible values alt and opt
                            </dd>
                        </dl>
                        <h2 id="returns">Returns</h2>
                        <p>None.</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">class PartitionedLs(object):
    &#34;&#34;&#34;
    Partitioned Least Square class
    &#34;&#34;&#34;

    def __init__(self, algorithm=&#34;alt&#34;):
        &#34;&#34;&#34;
            Constructor of Partioned Least Square Class

            Parameters
            ----------
            algorithm : string
                        String used to set some algorithm to choose to create
                        the model. possible values alt and opt


            Returns
            -------
            None.
        &#34;&#34;&#34;
        self.model = None
        self.algorithm = algorithm

    def fit(self, x, y, p):
        &#34;&#34;&#34;
            Fits a PartialLS Regression model to the given data

            Parameters
            ----------
            x : Matrix
                describing the examples
            y : Array
                vector with the output values for each example
            p : Matrix
                specifying how to partition the M attributes into K subsets.
                P{m,k} should be 1 if attribute number m belongs to partition k

            Returns
            -------
            None.
        &#34;&#34;&#34;
        if self.algorithm == &#34;opt&#34;:
            self.__fit_opt_nnls(x, y, p)
        elif self.algorithm == &#34;alt&#34;:
            self.__fit_alt_nnls(x, y, p)
        else:
            self.__fit_alt_nnls(x, y, p)

    def __fit_opt_nnls(self, x,
                       y, p):
        &#34;&#34;&#34;
            Fits a PartialLS OPT Regression model to the given data

            Parameters
            ----------
            x : Matrix
                describing the examples
            y : Array
                vector with the output values for each example
            p : Matrix
                specifying how to partition the M attributes into K subsets.
                P{m,k} should be 1 if attribute number m belongs to partition k

            Returns
            -------
            None.
        &#34;&#34;&#34;
        xo = hstack((x, ones((shape(x)[0], 1))))
        po = vstack(
            (hstack((p, zeros((shape(p)[0], 1)))), vec1(shape(p)[1] + 1)))

        k = shape(po)[1]

        b_start, results = (-1, [])

        for i in range(b_start + 1, 2 ** k):
            beta = array(indextobeta(i, k))
            xb = bmatrix(xo, po, beta)
            alpha = nnls(xb, y)[0]
            optval = norm(xo.dot(po * alpha.reshape(-1, 1)).dot(beta) - y)

            result = (optval, alpha[:-1], beta[:-1], alpha[-1] * beta[-1], p)
            results.append(result)

        optvals = [r[0] for r in results]
        optindex = optvals.index(min(optvals))

        (opt, a, b, t, p) = results[optindex]

        A = sum_elements(p * a.reshape(-1, 1), 0)
        b = b * A

        # substituting all 0.0 with 1.0
        for z in where(A == 0.0):
            A[z] = 1.0

        a = sum_elements((p * a.reshape(-1, 1)) / A, 1)

        self.model = (opt, a, b, t, p)

    def __fit_alt_nnls(self, x,
                       y, p,
                       n=20):
        &#34;&#34;&#34;
            Fits a PartialLS Alt Regression model to the given data

            Parameters
            ----------
            x : Matrix N * M
                matrix describing the examples
            y : vector
                vector with the output values for each example
            p : Matrix M * K
                specifying how to partition the M attributes into K subsets.
                P{m,k} should be 1 if attribute number m belongs to partition k
            n : int
                number of alternating loops to be performed, defaults to 20.

            Returns
            -------
            None.
        &#34;&#34;&#34;

        # Rewriting the problem in homogenous coordinates
        xo = hstack((x, ones((shape(x)[0], 1))))
        po = vstack((hstack((p, zeros((shape(p)[0], 1)))),
                     vec1(shape(p)[1] + 1)))

        m, k = shape(po)

        alpha = rand(m)
        beta = (rand(k) - 0.5) * 10
        t = rand()

        initvals = (0, alpha, beta, t, inf)

        i_start, alpha, beta, t, optval = initvals

        for i in range(i_start + 1, n):
            # nnls problem with fixed beta variables
            po_beta = sum_elements(po * beta, 1)
            xo_beta = xo * po_beta
            alpha = nnls(xo_beta, y)[0]
            alpha = checkalpha(alpha, po)

            sum_alpha = sum_elements(po * alpha.reshape(-1, 1), 0)
            po_alpha = sum_elements(po * sum_alpha, 1)
            alpha = alpha / po_alpha
            beta = beta * sum_alpha

            # ls problem with fixed alpha variables
            xo_alpha = xo.dot(po * alpha.reshape(-1, 1))
            beta = lstsq(xo_alpha, y, rcond=None)[0]
            optval = norm(xo.dot(po * alpha.reshape(-1, 1)).dot(beta) - y, 2)

        self.model = (optval, alpha[:-1], beta[:-1], alpha[-1] * beta[-1], p)

    def predict(self, x):
        &#34;&#34;&#34;
            Description
            Predicts points using the formula: f(X) = X * (P .* a) * b + t.

            Parameters
            ----------
            x : Matrix N * M
                    matrix describing the examples

            Returns
            -------
            out : Array
             contains the predictions of the given model on examples in X
        &#34;&#34;&#34;
        (_, alpha, beta, t, p) = self.model
        return array(x).dot(p * alpha.reshape(-1, 1)).dot(beta) + t</code></pre>
                    </details>
                    <h3>Methods</h3>
                    <dl>
                        <dt id="_base.PartitionedLs.fit"><code class="name flex">
                            <span>def <span class="ident">fit</span></span>(<span>self, x, y, p)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Fits a PartialLS Regression model to the given data</p>
                                <h2 id="parameters">Parameters</h2>
                                <dl>
                                    <dt><strong><code>x</code></strong> :&ensp;<code>Matrix</code></dt>
                                    <dd>describing the examples</dd>
                                    <dt><strong><code>y</code></strong> :&ensp;<code>Array</code></dt>
                                    <dd>vector with the output values for each example</dd>
                                    <dt><strong><code>p</code></strong> :&ensp;<code>Matrix</code></dt>
                                    <dd>specifying how to partition the M attributes into K subsets.
                                        P{m,k} should be 1 if attribute number m belongs to partition k
                                    </dd>
                                </dl>
                                <h2 id="returns">Returns</h2>
                                <p>None.</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def fit(self, x, y, p):
    &#34;&#34;&#34;
        Fits a PartialLS Regression model to the given data

        Parameters
        ----------
        x : Matrix
            describing the examples
        y : Array
            vector with the output values for each example
        p : Matrix
            specifying how to partition the M attributes into K subsets.
            P{m,k} should be 1 if attribute number m belongs to partition k

        Returns
        -------
        None.
    &#34;&#34;&#34;
    if self.algorithm == &#34;opt&#34;:
        self.__fit_opt_nnls(x, y, p)
    elif self.algorithm == &#34;alt&#34;:
        self.__fit_alt_nnls(x, y, p)
    else:
        self.__fit_alt_nnls(x, y, p)</code></pre>
                            </details>
                        </dd>
                        <dt id="_base.PartitionedLs.predict"><code class="name flex">
                            <span>def <span class="ident">predict</span></span>(<span>self, x)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Description
                                Predicts points using the formula: f(X) = X * (P .* a) * b + t.</p>
                                <h2 id="parameters">Parameters</h2>
                                <dl>
                                    <dt><strong><code>x</code></strong> :&ensp;<code>Matrix N * M</code></dt>
                                    <dd>matrix describing the examples</dd>
                                </dl>
                                <h2 id="returns">Returns</h2>
                                <dl>
                                    <dt><strong><code>out</code></strong> :&ensp;<code>Array</code></dt>
                                    <dd>&nbsp;</dd>
                                </dl>
                                <p>contains the predictions of the given model on examples in X</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def predict(self, x):
    &#34;&#34;&#34;
        Description
        Predicts points using the formula: f(X) = X * (P .* a) * b + t.

        Parameters
        ----------
        x : Matrix N * M
                matrix describing the examples

        Returns
        -------
        out : Array
         contains the predictions of the given model on examples in X
    &#34;&#34;&#34;
    (_, alpha, beta, t, p) = self.model
    return array(x).dot(p * alpha.reshape(-1, 1)).dot(beta) + t</code></pre>
                            </details>
                        </dd>
                    </dl>
                </dd>
            </dl>
        </section>
        <header>
            <h1 class="title">Module <code>_utils</code></h1>
        </header>
        <section id="section-intro">
            <p>Useful functions</p>
            <p>Developer:
                Omar Billotti</p>
            <p>Description:
                useful functions for the partitioned least squares algorithm</p>
            <details class="source">
                <summary>
                    <span>Expand source code</span>
                </summary>
                <pre><code class="python">#!/usr/bin/env python
&#34;&#34;&#34;
Useful functions

Developer:
Omar Billotti

Description:
useful functions for the partitioned least squares algorithm
&#34;&#34;&#34;
from numpy import zeros, sum


def checkalpha(a, p):
    &#34;&#34;&#34;
        checkalpha funtion

        Parameters
        ----------
        alpha : Array
        p : Matrix

        Returns
        -------
        out : Array
    &#34;&#34;&#34;
    suma = sum(p * a.reshape(-1, 1), 0)
    sump = sum(p, 0)
    for k in range(0, p.shape[1]):
        if suma[k] == 0.0:
            for m in range(0, p.shape[0]):
                if p[m][k] == 1:
                    a[m] = 1.0 / sump[k]
    return a


def vec1(n):
    &#34;&#34;&#34;
        Create an array with all elements a zero except the last element which
        will be the equal a 1.

        Parameters
        ----------
        n : integer

        Returns
        -------
        out : Array
               with all elements a zero except the last element which will be
               the equal a 1
    &#34;&#34;&#34;
    result = zeros((1, n))
    result[0][n - 1] = 1
    return result


def indextobeta(b, k):
    &#34;&#34;&#34;
       indextobeta funtion

        Parameters
        ----------
        b : integer

        k : integer

        Returns
        -------
        out : Array
              return 2 * bin(b,K) - 1 where bin(b,K) is a vector of K elements
              containing the binary representation of b.
    &#34;&#34;&#34;
    result = []
    for i in range(0, k):
        result.append(2 * (b % 2) - 1)
        b = b &gt;&gt; 1
    return result


def bmatrix(x, p, beta):
    &#34;&#34;&#34;
        bmatrix funtion

        Parameters
        ----------
        x : Matrix
        p : Matrix
        beta : Array

        Returns
        -------
        out : Matrix
              obtained multiplying each element in X to the associated
              weight in beta.
    &#34;&#34;&#34;
    pbeta = p * beta
    featuremul = sum(pbeta, 1)
    return x * featuremul</code></pre>
            </details>
        </section>
        <section>
        </section>
        <section>
        </section>
        <section>
            <h2 class="section-title" id="header-functions">Functions</h2>
            <dl>
                <dt id="_utils.bmatrix"><code class="name flex">
                    <span>def <span class="ident">bmatrix</span></span>(<span>x, p, beta)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>bmatrix funtion</p>
                        <h2 id="parameters">Parameters</h2>
                        <dl>
                            <dt><strong><code>x</code></strong> :&ensp;<code>Matrix</code></dt>
                            <dd>&nbsp;</dd>
                            <dt><strong><code>p</code></strong> :&ensp;<code>Matrix</code></dt>
                            <dd>&nbsp;</dd>
                            <dt><strong><code>beta</code></strong> :&ensp;<code>Array</code></dt>
                            <dd>&nbsp;</dd>
                        </dl>
                        <h2 id="returns">Returns</h2>
                        <dl>
                            <dt><strong><code>out</code></strong> :&ensp;<code>Matrix</code></dt>
                            <dd>obtained multiplying each element in X to the associated
                                weight in beta.
                            </dd>
                        </dl>
                    </div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def bmatrix(x, p, beta):
    &#34;&#34;&#34;
        bmatrix funtion

        Parameters
        ----------
        x : Matrix
        p : Matrix
        beta : Array

        Returns
        -------
        out : Matrix
              obtained multiplying each element in X to the associated
              weight in beta.
    &#34;&#34;&#34;
    pbeta = p * beta
    featuremul = sum(pbeta, 1)
    return x * featuremul</code></pre>
                    </details>
                </dd>
                <dt id="_utils.checkalpha"><code class="name flex">
                    <span>def <span class="ident">checkalpha</span></span>(<span>a, p)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>checkalpha funtion</p>
                        <h2 id="parameters">Parameters</h2>
                        <dl>
                            <dt><strong><code>alpha</code></strong> :&ensp;<code>Array</code></dt>
                            <dd>&nbsp;</dd>
                            <dt><strong><code>p</code></strong> :&ensp;<code>Matrix</code></dt>
                            <dd>&nbsp;</dd>
                        </dl>
                        <h2 id="returns">Returns</h2>
                        <dl>
                            <dt><strong><code>out</code></strong> :&ensp;<code>Array</code></dt>
                            <dd>&nbsp;</dd>
                        </dl>
                    </div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def checkalpha(a, p):
    &#34;&#34;&#34;
        checkalpha funtion

        Parameters
        ----------
        alpha : Array
        p : Matrix

        Returns
        -------
        out : Array
    &#34;&#34;&#34;
    suma = sum(p * a.reshape(-1, 1), 0)
    sump = sum(p, 0)
    for k in range(0, p.shape[1]):
        if suma[k] == 0.0:
            for m in range(0, p.shape[0]):
                if p[m][k] == 1:
                    a[m] = 1.0 / sump[k]
    return a</code></pre>
                    </details>
                </dd>
                <dt id="_utils.indextobeta"><code class="name flex">
                    <span>def <span class="ident">indextobeta</span></span>(<span>b, k)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>indextobeta funtion</p>
                        <p>Parameters</p>
                        <hr>
                        <p>b : integer</p>
                        <p>k : integer</p>
                        <p>Returns</p>
                        <hr>
                        <p>out : Array
                            return 2 * bin(b,K) - 1 where bin(b,K) is a vector of K elements
                            containing the binary representation of b.</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def indextobeta(b, k):
    &#34;&#34;&#34;
       indextobeta funtion

        Parameters
        ----------
        b : integer

        k : integer

        Returns
        -------
        out : Array
              return 2 * bin(b,K) - 1 where bin(b,K) is a vector of K elements
              containing the binary representation of b.
    &#34;&#34;&#34;
    result = []
    for i in range(0, k):
        result.append(2 * (b % 2) - 1)
        b = b &gt;&gt; 1
    return result</code></pre>
                    </details>
                </dd>
                <dt id="_utils.vec1"><code class="name flex">
                    <span>def <span class="ident">vec1</span></span>(<span>n)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Create an array with all elements a zero except the last element which
                        will be the equal a 1.</p>
                        <h2 id="parameters">Parameters</h2>
                        <dl>
                            <dt><strong><code>n</code></strong> :&ensp;<code>integer</code></dt>
                            <dd>&nbsp;</dd>
                        </dl>
                        <h2 id="returns">Returns</h2>
                        <dl>
                            <dt><strong><code>out</code></strong> :&ensp;<code>Array</code></dt>
                            <dd>with all elements a zero except the last element which will be
                                the equal a 1
                            </dd>
                        </dl>
                    </div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def vec1(n):
    &#34;&#34;&#34;
        Create an array with all elements a zero except the last element which
        will be the equal a 1.

        Parameters
        ----------
        n : integer

        Returns
        -------
        out : Array
               with all elements a zero except the last element which will be
               the equal a 1
    &#34;&#34;&#34;
    result = zeros((1, n))
    result[0][n - 1] = 1
    return result</code></pre>
                    </details>
                </dd>
            </dl>
        </section>
        <section>
        </section>
    </article>
    <nav id="sidebar">
        <h1><a href="../">HomePage</a></h1>
        <div class="toc">
            <ul></ul>
        </div>
        <ul id="index">
            <li><h3><a href="#header-classes">Classes</a></h3>
                <ul>
                    <li>
                        <h4><code><a title="_base.PartitionedLs" href="#_base.PartitionedLs">PartitionedLs</a></code>
                        </h4>
                        <ul class="">
                            <li><code><a title="_base.PartitionedLs.fit" href="#_base.PartitionedLs.fit">fit</a></code>
                            </li>
                            <li><code><a title="_base.PartitionedLs.predict"
                                         href="#_base.PartitionedLs.predict">predict</a></code></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><h3><a href="#header-functions">Functions</a></h3>
                <ul class="">
                    <li><code><a title="_utils.bmatrix" href="#_utils.bmatrix">bmatrix</a></code></li>
                    <li><code><a title="_utils.checkalpha" href="#_utils.checkalpha">checkalpha</a></code></li>
                    <li><code><a title="_utils.indextobeta" href="#_utils.indextobeta">indextobeta</a></code></li>
                    <li><code><a title="_utils.vec1" href="#_utils.vec1">vec1</a></code></li>
                </ul>
            </li>
        </ul>
    </nav>
</main>
</body>
</html>